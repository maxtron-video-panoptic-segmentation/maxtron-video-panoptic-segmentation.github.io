<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation">
  <meta property="og:title" content="MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation">
  <meta property="og:description" content="MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation">
  <meta property="og:image" content="https://maxtron-video-panoptic-segmentation.github.io/static/images/teaser.png">
  <meta property="twitter:title" content="MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation">
  <meta property="twitter:description" content="MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation">
  <meta property="twitter:image" content="https://maxtron-video-panoptic-segmentation.github.io/static/images/teaser.png">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Video Panoptic Segmentation, Video Instance Segmentation, Trajectory Attention">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-G62L2JMGEW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    
    function gtag(){
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-G62L2JMGEW');
  </script>
  <!-- Google tag (gtag.js) -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- Title/Authors/Institutions/Links -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- Title -->
          <h1 class="title is-1 publication-title">MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation</h1>
          <!-- <h2 class="title is-size-3">arXiv</h2> -->
          <!-- Title -->
          
          <!-- Authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tacju.github.io/">Ju He</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yucornetto.github.io/">Qihang Yu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://dlsrbgg33.github.io/">Inkyu Shin</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/view/xueqingdeng7/home">Xueqing Deng</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://xiaohuishen.github.io/">Xiaohui Shen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a><sup>2</sup></span>
          </div>
          <!-- Authors -->
          
          <!-- Institutions -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Johns Hopkins University</span>,
            <span class="author-block"><sup>2</sup>ByteDance</span>,
            <span class="author-block"><sup>3</sup>KAIST</span>,
          </div>
          <!-- Institutions -->

          <!-- PDF Links -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2311.18537.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2311.18537"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://youtu.be/zTmUaudo_5Q"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/TACJu/MaXTron"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code & Models</span>
                  </a>
              </span>
            </div>

          </div>
          <!-- PDF Links -->
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Title/Authors/Institutions/Links -->


<!-- Teaser Videos -->
<section class="hero teaser">
  <div class="container"> 
    <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column" style="padding: 0px">
            <img src="./static/images/teaser.png">
          </div>
        </div>
    </div>
    <h2 class="subtitle has-text-centered">
        <p>MaXTron is a simple yet effective unified meta-architecture for video segmentation.</p>
        <p>It enriches existing clip-level segmenters by improving both the within-clip and cross-clip tracking ability.
    </h2>
  </div>
</section>
<!-- Teaser Videos -->


<!-- Main Body -->
<section class="section">
  <div class="container">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Video panoptic segmentation requires consistently segmenting (for both 'thing' and 'stuff' classes) and tracking objects in a video over time. In this work, we present 
            MaXTron, a general framework that exploits Mask XFormer with Trajectory Attention to tackle the task. MaXTron enriches an off-the-shelf mask transformer by leveraging trajectory attention. 
            The deployed mask transformer takes as input a short clip consisting of only a few frames and predicts the clip-level segmentation. To enhance the temporal consistency, 
            MaXTron employs within-clip and cross-clip tracking modules, efficiently utilizing trajectory attention. Originally designed for video classification, trajectory attention learns to model the temporal 
            correspondences between neighboring frames and aggregates information along the estimated motion paths. However, it is nontrivial to directly extend trajectory attention to the per-pixel dense prediction tasks due to its quadratic dependency on input size. 
            To alleviate the issue, we propose to adapt the trajectory attention for both the dense pixel features and object queries, aiming to improve the shortterm and long-term tracking results, respectively. Particularly, in our within-clip tracking module, 
            we propose axial-trajectory attention that effectively computes the trajectory attention for tracking dense pixels sequentially along the heightand width-axes. The axial decomposition significantly reduces the computational complexity for dense pixel features. 
            In our cross-clip tracking module, since the object queries in mask transformer are learned to encode the object information, we are able to capture the long-term temporal connections by applying trajectory attention to object queries, which learns to track each object across different clips. 
            Without bells and whistles, MaXTron demonstrates state-of-the-art performances on video segmentation benchmarks. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract -->

    &nbsp;
    

    <!-- Methodology -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methodology</h2>
        <img class="architecture" src="./static/images/arch.png" alt="">
        <h2 class="subtitle has-text-centered">
          An overview of the proposed MaXTron.
        </h2>
      </div>
    </div>
    <!--/ Methodology -->

    <!-- &nbsp; -->

    <!-- Paper video -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/zTmUaudo_5Q?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video -->
  </div>
<!-- </section> -->
<!-- Main Body -->

<!-- Results -->
<!-- <section class="section"> -->
  <div class="container"> 
    <div class="hero-body">
      <div class="column is-centered has-text-centered">
        <h2 class="title is-3">Demos </h2>
      </div>
    </div>

    <video id="vipseg0" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/0.mp4" type="video/mp4">
    </video>
    <video id="vipseg1" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/1.mp4" type="video/mp4">
    </video>
    <video id="vipseg2" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/2.mp4" type="video/mp4">
    </video>
    <video id="vipseg3" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/3.mp4" type="video/mp4">
    </video>
    <video id="vipseg4" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/4.mp4" type="video/mp4">
    </video>
    <video id="vipseg5" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/5.mp4" type="video/mp4">
    </video>
    <!-- <img class="labels" src="./static/images/labels.png"> -->
    <h2 class="subtitle has-text-centered">Qualitative results on VIPSeg Dataset.</h2>

    <!-- <div style="margin-bottom: 70px;"></div>

    <video id="nuscenes1" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/nuscenes/scene-0099.mp4" type="video/mp4">
    </video>
    <video id="nuscenes2" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/nuscenes/scene-0104.mp4" type="video/mp4">
    </video>
    <video id="nuscenes3" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/nuscenes/scene-0556.mp4" type="video/mp4">
    </video>
    <video id="nuscenes4" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/nuscenes/scene-0521.mp4" type="video/mp4">
    </video>
    <video id="nuscenes5" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/nuscenes/scene-0794.mp4" type="video/mp4">
    </video>
    <video id="nuscenes6" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/nuscenes/scene-0553.mp4" type="video/mp4">
    </video>
    <img class="labels" src="./static/images/labels.png">
    <h2 class="subtitle has-text-centered">Additional results on nuScenes Dataset.</h2> -->

  </div>
</section>
<!-- Results -->


<!-- Limitations -->
<!-- <section class="section">
  <div class="container"> 
    <div class="hero-body">
      <div class="column is-centered has-text-centered">
        <h2 class="title is-3">Limitations </h2>
      </div>
    </div>

    <video id="waymo3" controls autoplay muted loop playsinline width="100%">
      <source src="./static/videos/waymo/segment-1457696187335927618_595_027_615_027.mp4" type="video/mp4">
    </video>
    <img class="labels" src="./static/images/labels.png">
    <h2 class="subtitle has-text-centered"> Object shadows are modeled as independently moving on the ground.</h2>

    <div style="margin-bottom: 70px;"></div>

  </div>
</section> -->
<!-- Limitations -->


<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container">
    <!-- Abstract -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">BibTeX</h2>
        <pre><code>@misc{he2023maxtron,
          title={MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation}, 
          author={Ju He and Qihang Yu and Inkyu Shin and Xueqing Deng and Xiaohui Shen and Alan Yuille and Liang-Chieh Chen},
          year={2023},
          eprint={2311.18537},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
        }</code></pre>
      </div>
    </div>
  </div>
</section>
<!-- BibTeX -->


<!-- Footer -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/maxtron-video-panoptic-segmentation/maxtron-video-panoptic-segmentation.github.io" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<!-- Footer -->


</body>
</html>
